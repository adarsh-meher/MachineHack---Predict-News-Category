{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MH-Predict News category.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adarsh-meher/MachineHack---Predict-News-Category/blob/master/MH_Predict_News_category.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhluJ1iGF_ao",
        "colab_type": "code",
        "outputId": "fb906528-678f-4461-866f-f3141d96a775",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install fasttext\n",
        "!pip install torchtext\n",
        "!pip install transformers"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting fasttext\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/10/61/2e01f1397ec533756c1d893c22d9d5ed3fce3a6e4af1976e0d86bb13ea97/fasttext-0.9.1.tar.gz (57kB)\n",
            "\r\u001b[K     |█████▊                          | 10kB 31.0MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 20kB 3.0MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 30kB 3.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 40kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 51kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 2.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.6/dist-packages (from fasttext) (2.5.0)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from fasttext) (46.1.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fasttext) (1.18.3)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.1-cp36-cp36m-linux_x86_64.whl size=2385709 sha256=e486afe0f870545a7ab72d2ec44341cba00b70097e544ec46d1420c0ecfff327\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/f0/04/caa82c912aee89ce76358ff954f3f0729b7577c8ff23a292e3\n",
            "Successfully built fasttext\n",
            "Installing collected packages: fasttext\n",
            "Successfully installed fasttext-0.9.1\n",
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.6/dist-packages (0.3.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchtext) (1.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext) (4.38.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torchtext) (2.21.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchtext) (1.18.3)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (3.0.4)\n",
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/78/92cedda05552398352ed9784908b834ee32a0bd071a9b32de287327370b7/transformers-2.8.0-py3-none-any.whl (563kB)\n",
            "\u001b[K     |████████████████████████████████| 573kB 4.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/50/93509f906a40bffd7d175f97fd75ea328ad9bd91f48f59c4bd084c94a25e/sacremoses-0.0.41.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 22.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Collecting tokenizers==0.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7MB 18.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/2c/8df20f3ac6c22ac224fff307ebc102818206c53fc454ecd37d8ac2060df5/sentencepiece-0.1.86-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 49.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.12.43)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.38.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.5)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.43 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.15.43)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.43->boto3->transformers) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.43->boto3->transformers) (2.8.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.41-cp36-none-any.whl size=893334 sha256=093a75c5694b67298b04d9d01d9f12fd7edadae53eaba1ed2b850d00197910cf\n",
            "  Stored in directory: /root/.cache/pip/wheels/22/5a/d4/b020a81249de7dc63758a34222feaa668dbe8ebfe9170cc9b1\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, sentencepiece, transformers\n",
            "Successfully installed sacremoses-0.0.41 sentencepiece-0.1.86 tokenizers-0.5.2 transformers-2.8.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTNxdY3NEh3m",
        "colab_type": "code",
        "outputId": "a42a331b-e292-47ef-978a-e1e62ae28cab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "!git clone https://github.com/adarsh-meher/MachineHack---Predict-News-Category.git\n",
        "import os\n",
        "os.chdir('/content/MachineHack---Predict-News-Category/')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'MachineHack---Predict-News-Category'...\n",
            "remote: Enumerating objects: 18, done.\u001b[K\n",
            "remote: Counting objects:   5% (1/18)\u001b[K\rremote: Counting objects:  11% (2/18)\u001b[K\rremote: Counting objects:  16% (3/18)\u001b[K\rremote: Counting objects:  22% (4/18)\u001b[K\rremote: Counting objects:  27% (5/18)\u001b[K\rremote: Counting objects:  33% (6/18)\u001b[K\rremote: Counting objects:  38% (7/18)\u001b[K\rremote: Counting objects:  44% (8/18)\u001b[K\rremote: Counting objects:  50% (9/18)\u001b[K\rremote: Counting objects:  55% (10/18)\u001b[K\rremote: Counting objects:  61% (11/18)\u001b[K\rremote: Counting objects:  66% (12/18)\u001b[K\rremote: Counting objects:  72% (13/18)\u001b[K\rremote: Counting objects:  77% (14/18)\u001b[K\rremote: Counting objects:  83% (15/18)\u001b[K\rremote: Counting objects:  88% (16/18)\u001b[K\rremote: Counting objects:  94% (17/18)\u001b[K\rremote: Counting objects: 100% (18/18)\u001b[K\rremote: Counting objects: 100% (18/18), done.\u001b[K\n",
            "remote: Compressing objects:   5% (1/17)\u001b[K\rremote: Compressing objects:  11% (2/17)\u001b[K\rremote: Compressing objects:  17% (3/17)\u001b[K\rremote: Compressing objects:  23% (4/17)\u001b[K\rremote: Compressing objects:  29% (5/17)\u001b[K\rremote: Compressing objects:  35% (6/17)\u001b[K\rremote: Compressing objects:  41% (7/17)\u001b[K\rremote: Compressing objects:  47% (8/17)\u001b[K\rremote: Compressing objects:  52% (9/17)\u001b[K\rremote: Compressing objects:  58% (10/17)\u001b[K\rremote: Compressing objects:  64% (11/17)\u001b[K\rremote: Compressing objects:  70% (12/17)\u001b[K\rremote: Compressing objects:  76% (13/17)\u001b[K\rremote: Compressing objects:  82% (14/17)\u001b[K\rremote: Compressing objects:  88% (15/17)\u001b[K\rremote: Compressing objects:  94% (16/17)\u001b[K\rremote: Compressing objects: 100% (17/17)\u001b[K\rremote: Compressing objects: 100% (17/17), done.\u001b[K\n",
            "remote: Total 18 (delta 3), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (18/18), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMCECbfwEl9W",
        "colab_type": "code",
        "outputId": "359bff2e-b05e-4cd8-ab7d-90975eab7819",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy as sc\n",
        "import seaborn as sb\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import nltk\n",
        "import gensim as G\n",
        "import spacy as S\n",
        "import fasttext as ft"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxlU3BkILiKg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6YKflyuFMlQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "news_data = pd.ExcelFile('Data_Train.xlsx').parse('Sheet1')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnKFlRRnHpd0",
        "colab_type": "code",
        "outputId": "76af8bc7-4c87-4ffe-ce47-8a617c12fdf2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "news_data.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>STORY</th>\n",
              "      <th>SECTION</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>But the most painful was the huge reversal in ...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>How formidable is the opposition alliance amon...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Most Asian currencies were trading lower today...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>If you want to answer any question, click on ‘...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>In global markets, gold prices edged up today ...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               STORY  SECTION\n",
              "0  But the most painful was the huge reversal in ...        3\n",
              "1  How formidable is the opposition alliance amon...        0\n",
              "2  Most Asian currencies were trading lower today...        3\n",
              "3  If you want to answer any question, click on ‘...        1\n",
              "4  In global markets, gold prices edged up today ...        3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhzU_blAHrEM",
        "colab_type": "code",
        "outputId": "c2ce46d5-8162-4344-9c98-a682dafa5259",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        }
      },
      "source": [
        "#### Counts of news category\n",
        "print(news_data['SECTION'].value_counts()/news_data.shape[0])\n",
        "\n",
        "'''\n",
        "Politics: 0\n",
        "Technology: 1\n",
        "Entertainment: 2\n",
        "Business: 3\n",
        "'''\n",
        "\n",
        "### no imbalance in categories\n",
        "\n",
        "target_to_name_map = {0:'Politics',1:\"Technology\",2:\"Entertainment\",3:\"Business\"}"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1    0.363398\n",
            "2    0.252229\n",
            "0    0.221028\n",
            "3    0.163346\n",
            "Name: SECTION, dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lj2Ze45TH2M8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#### Creating a test set assuming similar proportion of categories in target\n",
        "news_train,news_test,target_train,target_test = train_test_split(news_data.drop(['SECTION'],axis = 1),news_data['SECTION'],test_size = 0.2,stratify = news_data['SECTION'])\n",
        "news_train.index,target_train.index = range(news_train.shape[0]),range(news_train.shape[0])\n",
        "news_test.index,target_test.index = range(news_test.shape[0]),range(news_test.shape[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKvA-6KcL5Wh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ky6gPFeaMvVB",
        "colab_type": "text"
      },
      "source": [
        "## ***Analyzing news_train texts***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8--4-z-yL66Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.concat([news_train.rename(columns = {'STORY' : 'text'}),pd.Series(target_train,name = 'target')],axis = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnL7BS-jM9kP",
        "colab_type": "code",
        "outputId": "2b2ac31e-46ad-4f53-9656-4af22c29aa55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The 10-year bond yield was trading at 7.4% fro...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Further, Google said it verifies the identity ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>New Delhi: Social media intermediaries and the...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The national party which is gradually gaining ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Modi will hold three public meetings in the po...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  target\n",
              "0  The 10-year bond yield was trading at 7.4% fro...       3\n",
              "1  Further, Google said it verifies the identity ...       0\n",
              "2  New Delhi: Social media intermediaries and the...       0\n",
              "3  The national party which is gradually gaining ...       0\n",
              "4  Modi will hold three public meetings in the po...       0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DL1Rs3GyNF52",
        "colab_type": "code",
        "outputId": "98b7032f-10cf-4f8f-9b91-ada7eee3f909",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "from nltk.tokenize import sent_tokenize,word_tokenize\n",
        "from nltk.probability import FreqDist\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer,LancasterStemmer\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"punkt\")\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "ps = PorterStemmer()\n",
        "ls = LancasterStemmer()\n",
        "wns = WordNetLemmatizer()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "al8O1pT_-MtF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##### Freq Dist of all words for all categories except stopwords\n",
        "tokens = [ y for x in df['text'].values for y in word_tokenize(x) if y.lower() not in stop_words and y.isalpha()]\n",
        "tokens_fdist = FreqDist(tokens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ipEX10oqju3",
        "colab_type": "code",
        "outputId": "711978e6-c6e3-42c2-b736-90d6c2b26fa7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "#### Freq distribution of words for each category\n",
        "token_cat = {}\n",
        "token_cat_fdist = {}\n",
        "for i in df['target'].unique():\n",
        "  print(target_to_name_map[i])\n",
        "  token_cat[target_to_name_map[i]] = [ y for x in df[df['target'] == i]['text'].values for y in word_tokenize(x) if y.lower() not in stop_words and y.isalpha() ]\n",
        "  token_cat_fdist[target_to_name_map[i]] = FreqDist(token_cat[target_to_name_map[i]]) "
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Business\n",
            "Politics\n",
            "Technology\n",
            "Entertainment\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqvPcs8y_ULh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#### Dataframe to show for each category the top n words\n",
        "n = 100\n",
        "top_words_each_cat = pd.DataFrame({\"Technology\" : [i for i,v in token_cat_fdist[\"Technology\"].most_common(n)],\n",
        "                                      \"Politics\" : [i for i,v in token_cat_fdist[\"Politics\"].most_common(n)],\n",
        "                                      \"Entertainment\" : [i for i,v in token_cat_fdist[\"Entertainment\"].most_common(n)],\n",
        "                                      \"Business\" : [i for i,v in token_cat_fdist[\"Business\"].most_common(n)]},index=range(n))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZ9kHmEc_UJp",
        "colab_type": "code",
        "outputId": "e1b1114d-9339-4610-fadc-2d371221a808",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "source": [
        "top_words_each_cat"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Technology</th>\n",
              "      <th>Politics</th>\n",
              "      <th>Entertainment</th>\n",
              "      <th>Business</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>also</td>\n",
              "      <td>BJP</td>\n",
              "      <td>film</td>\n",
              "      <td>said</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>said</td>\n",
              "      <td>Congress</td>\n",
              "      <td>said</td>\n",
              "      <td>year</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>India</td>\n",
              "      <td>said</td>\n",
              "      <td>also</td>\n",
              "      <td>India</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>new</td>\n",
              "      <td>party</td>\n",
              "      <td>like</td>\n",
              "      <td>market</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Apple</td>\n",
              "      <td>Modi</td>\n",
              "      <td>actor</td>\n",
              "      <td>growth</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>sale</td>\n",
              "      <td>come</td>\n",
              "      <td>things</td>\n",
              "      <td>order</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>products</td>\n",
              "      <td>ruling</td>\n",
              "      <td>among</td>\n",
              "      <td>cut</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>variant</td>\n",
              "      <td>issue</td>\n",
              "      <td>still</td>\n",
              "      <td>increase</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>system</td>\n",
              "      <td>crore</td>\n",
              "      <td>America</td>\n",
              "      <td>rates</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>many</td>\n",
              "      <td>may</td>\n",
              "      <td>never</td>\n",
              "      <td>expected</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Technology  Politics Entertainment  Business\n",
              "0        also       BJP          film      said\n",
              "1        said  Congress          said      year\n",
              "2       India      said          also     India\n",
              "3         new     party          like    market\n",
              "4       Apple      Modi         actor    growth\n",
              "..        ...       ...           ...       ...\n",
              "95       sale      come        things     order\n",
              "96   products    ruling         among       cut\n",
              "97    variant     issue         still  increase\n",
              "98     system     crore       America     rates\n",
              "99       many       may         never  expected\n",
              "\n",
              "[100 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwFdicsw_UFQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#### Extract set of words that appear both of any of the two categories\n",
        "from itertools import combinations\n",
        "common_words = []\n",
        "for i in combinations(target_to_name_map.values(),2):\n",
        "  [ common_words.append(x) for x in set(top_words_each_cat[i[0]]).intersection(set(top_words_each_cat[i[1]])) ]\n",
        "\n",
        "common_words = set(list(common_words))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yne8DudF_UCY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#### Dataframe to show for each category the bottom n words\n",
        "n = 100\n",
        "least_words_each_cat = pd.DataFrame({\"Technology\" : [i for i,v in token_cat_fdist[\"Technology\"].most_common()[-n:]],\n",
        "                                      \"Politics\" : [i for i,v in token_cat_fdist[\"Politics\"].most_common()[-n:]],\n",
        "                                      \"Entertainment\" : [i for i,v in token_cat_fdist[\"Entertainment\"].most_common()[-n:]],\n",
        "                                      \"Business\" : [i for i,v in token_cat_fdist[\"Business\"].most_common()[-n:]]},index=range(n))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrhitv74_UAP",
        "colab_type": "code",
        "outputId": "022aaef6-556d-4f54-93db-f8fbead90e4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "source": [
        "least_words_each_cat"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Technology</th>\n",
              "      <th>Politics</th>\n",
              "      <th>Entertainment</th>\n",
              "      <th>Business</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>furore</td>\n",
              "      <td>equidistance</td>\n",
              "      <td>asusual</td>\n",
              "      <td>James</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>pornographic</td>\n",
              "      <td>KV</td>\n",
              "      <td>Entire</td>\n",
              "      <td>Petersburg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>performers</td>\n",
              "      <td>axing</td>\n",
              "      <td>GREAT</td>\n",
              "      <td>ought</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>justified</td>\n",
              "      <td>Hibi</td>\n",
              "      <td>Chhabra</td>\n",
              "      <td>tell</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Shradha</td>\n",
              "      <td>Eden</td>\n",
              "      <td>Jus</td>\n",
              "      <td>slamming</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>Quora</td>\n",
              "      <td>leher</td>\n",
              "      <td>benefiting</td>\n",
              "      <td>accompanied</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>similarity</td>\n",
              "      <td>Mehiwal</td>\n",
              "      <td>grade</td>\n",
              "      <td>reminiscent</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>nationally</td>\n",
              "      <td>Chandan</td>\n",
              "      <td>setup</td>\n",
              "      <td>fakes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>bound</td>\n",
              "      <td>Gappu</td>\n",
              "      <td>kickstarted</td>\n",
              "      <td>Aniruddha</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>segregates</td>\n",
              "      <td>Mulayamji</td>\n",
              "      <td>retaining</td>\n",
              "      <td>Share</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Technology      Politics Entertainment     Business\n",
              "0         furore  equidistance       asusual        James\n",
              "1   pornographic            KV        Entire   Petersburg\n",
              "2     performers         axing         GREAT        ought\n",
              "3      justified          Hibi       Chhabra         tell\n",
              "4        Shradha          Eden           Jus     slamming\n",
              "..           ...           ...           ...          ...\n",
              "95         Quora         leher    benefiting  accompanied\n",
              "96    similarity       Mehiwal         grade  reminiscent\n",
              "97    nationally       Chandan         setup        fakes\n",
              "98         bound         Gappu   kickstarted    Aniruddha\n",
              "99    segregates     Mulayamji     retaining        Share\n",
              "\n",
              "[100 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGAJV_rX_T5g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTSCZEjhnHBv",
        "colab_type": "text"
      },
      "source": [
        "# **Cleaning text data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urpJz_yV8vFs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from html.parser import HTMLParser\n",
        "import re\n",
        "import string"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXoFBDlFnGzz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "contrac = {'s' : 'is','t':'not','ve' : 'have','d' : 'had', '':'a'}\n",
        "\n",
        "def clean_text(x):\n",
        "  ###### Remove HTML characters\n",
        "  x = HTMLParser().unescape(x)\n",
        "\n",
        "  ##### Treating apostrophes/contraction words\n",
        "  #x = ' '.join([ w.split('\\'')[0].lower()[:-1]+' '+contrac[w.split('\\'')[1].lower()] if '\\'' in w else w for sent in sent_tokenize(x) for w in sent.split()  ])\n",
        "  word_list = []\n",
        "  for sent in sent_tokenize(x):\n",
        "    for w in sent.split():\n",
        "      if '\\'' in w:\n",
        "        w1 = w.split('\\'')[0].lower()[:-1]\n",
        "        try:\n",
        "          c1 = w.split('\\'')[1]/lower()\n",
        "          w_new = w1 + ' '+ contrac[w2]\n",
        "          word_list.append(w_new)\n",
        "        except:\n",
        "          w_new = w1\n",
        "          word_list.append(w_new)\n",
        "      else:\n",
        "        word_list.append(w)\n",
        "    \n",
        "  x = ' '.join(word_list) \n",
        "\n",
        "  ##### Removing stopwords and stemming words to its base form\n",
        "  x = ' '.join([ ps.stem(w) for w in word_tokenize(x) if w not in stop_words])\n",
        "\n",
        "  ##### Remove punctuations\n",
        "  table = str.maketrans('', '', string.punctuation)\n",
        "  x = ' '.join([w.translate(table) for w in word_tokenize(x) ])\n",
        "\n",
        "  ##### Replace digits with 'numeral' string to denote presence of number. This can be used in business category as presence of number in that category is certainly possible\n",
        "  x = ' '.join([ 'numeral' if w.isdigit() else w for w in word_tokenize(x)])\n",
        "\n",
        "  ##### Remove presence of url/https links\n",
        "  url_pattern = r'''(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\".,<>?«»“”‘’]))'''\n",
        "  x = re.sub(url_pattern, ' ', x)\n",
        "\n",
        "  ##### Remove nonascii characters\n",
        "  x = ''.join([chr for chr in x if ord(chr) < 128])\n",
        "\n",
        "  ##### strip and leading/training spaces and convert all words to lowercase\n",
        "  x = x.strip().lower()\n",
        "\n",
        "  return x\n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fiq0ZwrwnL1i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "4e2d055d-ed13-4eff-bbaa-7787482708b7"
      },
      "source": [
        "news_train['clean_text'] = news_train['STORY'].apply(lambda x : clean_text(x))\n",
        "news_test['clean_text'] = news_test['STORY'].apply(lambda x : clean_text(x))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: The unescape method is deprecated and will be removed in 3.5, use html.unescape() instead.\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOhogG30nLtz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.concat([target_train,news_train.drop(['STORY'],axis = 1)],axis = 1).to_csv('News_Train.csv',index = False)\n",
        "pd.concat([target_test,news_test.drop(['STORY'],axis = 1)],axis = 1).to_csv('News_Test.csv',index = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j33fvsueND_v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ot6E04SRUPeu",
        "colab_type": "text"
      },
      "source": [
        "### **`Classification using Torch`**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIv8yB_158Wl",
        "colab_type": "text"
      },
      "source": [
        "Simple LSTM Baseline model using TorchText"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fiBbpPMVeKd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch \n",
        "from torchtext.data import Field,BucketIterator,TabularDataset,LabelField"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJBOFaRwm0Te",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_field = Field(tokenize = word_tokenize,lower = True)\n",
        "label_field = LabelField(use_vocab = False)\n",
        "datafields = [('SECTION',label_field),('clean_text',text_field)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkjQuzQ_m0RI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = TabularDataset(path = os.path.join(os.getcwd(),'News_Train.csv'),format = \"csv\",skip_header=False,fields=datafields)\n",
        "test = TabularDataset(path = os.path.join(os.getcwd(),'News_Test.csv'),format = \"csv\",skip_header=False,fields=datafields)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ril-Fh3wm0Pa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_field.build_vocab(train,max_size = 5000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBR1XmFLm0M9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_iter,test_iter = BucketIterator.splits((train,test),batch_size=(64,64),sort_key=lambda x: len(x.clean_text),sort_within_batch=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyI1dOT1m0JT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qy3i2oZAm0Gz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5bNCSklm0ET",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnhDnZ_Bm0Cs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xa-xwEu-m0As",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrh4CVQVmz-g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZhcwBzYmz8Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ypLdvl3mz6K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s56C5xBjmzzR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QMM7PiemzxO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Czw5AKw6mzu6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_C2UIDYmzr9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVNFaQ-7mzqZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5r70_eJmzod",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-Y1gJ9-mzjm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUrjC9immzfe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}