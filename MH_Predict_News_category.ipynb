{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MH-Predict News category.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adarsh-meher/MachineHack---Predict-News-Category/blob/master/MH_Predict_News_category.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhluJ1iGF_ao",
        "colab_type": "code",
        "outputId": "09595bbd-ed59-4707-f703-9048ec011b9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install fasttext\n",
        "!pip install torchtext\n",
        "!pip install transformers"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting fasttext\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/10/61/2e01f1397ec533756c1d893c22d9d5ed3fce3a6e4af1976e0d86bb13ea97/fasttext-0.9.1.tar.gz (57kB)\n",
            "\r\u001b[K     |█████▊                          | 10kB 16.5MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 20kB 1.6MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 30kB 2.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 40kB 2.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 51kB 1.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 1.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.6/dist-packages (from fasttext) (2.5.0)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from fasttext) (46.1.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fasttext) (1.18.3)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.1-cp36-cp36m-linux_x86_64.whl size=2385714 sha256=c26dd3d112037c1e5aebd1c0e137c7ba395904009a9b14ef50492efdb3702308\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/f0/04/caa82c912aee89ce76358ff954f3f0729b7577c8ff23a292e3\n",
            "Successfully built fasttext\n",
            "Installing collected packages: fasttext\n",
            "Successfully installed fasttext-0.9.1\n",
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.6/dist-packages (0.3.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext) (4.38.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchtext) (1.18.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torchtext) (2.21.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchtext) (1.4.0)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (2020.4.5.1)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (1.24.3)\n",
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/78/92cedda05552398352ed9784908b834ee32a0bd071a9b32de287327370b7/transformers-2.8.0-py3-none-any.whl (563kB)\n",
            "\u001b[K     |████████████████████████████████| 573kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Collecting tokenizers==0.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7MB 42.2MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/2c/8df20f3ac6c22ac224fff307ebc102818206c53fc454ecd37d8ac2060df5/sentencepiece-0.1.86-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 41.2MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/50/93509f906a40bffd7d175f97fd75ea328ad9bd91f48f59c4bd084c94a25e/sacremoses-0.0.41.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 40.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.38.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.12.43)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.43 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.15.43)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.5)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.43->boto3->transformers) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.43->boto3->transformers) (0.15.2)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.41-cp36-none-any.whl size=893334 sha256=a9e51578be9b6e26cada3ad40b306dbeeec238c9d12ce96efef9387f0f8c4eb3\n",
            "  Stored in directory: /root/.cache/pip/wheels/22/5a/d4/b020a81249de7dc63758a34222feaa668dbe8ebfe9170cc9b1\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.41 sentencepiece-0.1.86 tokenizers-0.5.2 transformers-2.8.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTNxdY3NEh3m",
        "colab_type": "code",
        "outputId": "43995b31-8d0e-472a-f631-9b41005a6c06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "!git clone https://github.com/adarsh-meher/MachineHack---Predict-News-Category.git\n",
        "import os\n",
        "os.chdir('/content/MachineHack---Predict-News-Category/')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'MachineHack---Predict-News-Category'...\n",
            "remote: Enumerating objects: 21, done.\u001b[K\n",
            "remote: Counting objects: 100% (21/21), done.\u001b[K\n",
            "remote: Compressing objects: 100% (20/20), done.\u001b[K\n",
            "remote: Total 21 (delta 4), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (21/21), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMCECbfwEl9W",
        "colab_type": "code",
        "outputId": "e8d0ae3a-9f3b-47d6-9b0e-e565a08c46f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy as sc\n",
        "import seaborn as sb\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import nltk\n",
        "import gensim as G\n",
        "import spacy as S\n",
        "import fasttext as ft"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxlU3BkILiKg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6YKflyuFMlQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "news_data = pd.ExcelFile('Data_Train.xlsx').parse('Sheet1')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnKFlRRnHpd0",
        "colab_type": "code",
        "outputId": "ee8ebf81-4d24-43b0-99b6-2a6a193543e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "news_data.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>STORY</th>\n",
              "      <th>SECTION</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>But the most painful was the huge reversal in ...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>How formidable is the opposition alliance amon...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Most Asian currencies were trading lower today...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>If you want to answer any question, click on ‘...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>In global markets, gold prices edged up today ...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               STORY  SECTION\n",
              "0  But the most painful was the huge reversal in ...        3\n",
              "1  How formidable is the opposition alliance amon...        0\n",
              "2  Most Asian currencies were trading lower today...        3\n",
              "3  If you want to answer any question, click on ‘...        1\n",
              "4  In global markets, gold prices edged up today ...        3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhzU_blAHrEM",
        "colab_type": "code",
        "outputId": "91b0bcbb-62a3-471f-811b-95a0005fe3f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        }
      },
      "source": [
        "#### Counts of news category\n",
        "print(news_data['SECTION'].value_counts()/news_data.shape[0])\n",
        "\n",
        "'''\n",
        "Politics: 0\n",
        "Technology: 1\n",
        "Entertainment: 2\n",
        "Business: 3\n",
        "'''\n",
        "\n",
        "### no imbalance in categories\n",
        "\n",
        "target_to_name_map = {0:'Politics',1:\"Technology\",2:\"Entertainment\",3:\"Business\"}"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1    0.363398\n",
            "2    0.252229\n",
            "0    0.221028\n",
            "3    0.163346\n",
            "Name: SECTION, dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lj2Ze45TH2M8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#### Creating a test set assuming similar proportion of categories in target\n",
        "news_train,news_test,target_train,target_test = train_test_split(news_data.drop(['SECTION'],axis = 1),news_data['SECTION'],test_size = 0.2,stratify = news_data['SECTION'])\n",
        "news_train.index,target_train.index = range(news_train.shape[0]),range(news_train.shape[0])\n",
        "news_test.index,target_test.index = range(news_test.shape[0]),range(news_test.shape[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKvA-6KcL5Wh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ky6gPFeaMvVB",
        "colab_type": "text"
      },
      "source": [
        "## ***Analyzing news_train texts***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8--4-z-yL66Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.concat([news_train.rename(columns = {'STORY' : 'text'}),pd.Series(target_train,name = 'target')],axis = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnL7BS-jM9kP",
        "colab_type": "code",
        "outputId": "ecd5a5b3-19c4-40f1-8174-4fbfb955e326",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The first season of the show will represent Th...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Fusion skills give companies and people a fram...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The president-elect of Ukraine does not have a...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Singer Rob Thomas says he owes it to guitar le...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Lau did not share any more details of the plan...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  target\n",
              "0  The first season of the show will represent Th...       2\n",
              "1  Fusion skills give companies and people a fram...       1\n",
              "2  The president-elect of Ukraine does not have a...       2\n",
              "3  Singer Rob Thomas says he owes it to guitar le...       2\n",
              "4  Lau did not share any more details of the plan...       1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DL1Rs3GyNF52",
        "colab_type": "code",
        "outputId": "96164d0f-194e-4266-f782-5ce8c79f0bf0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "from nltk.tokenize import sent_tokenize,word_tokenize\n",
        "from nltk.probability import FreqDist\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer,LancasterStemmer\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"punkt\")\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "ps = PorterStemmer()\n",
        "ls = LancasterStemmer()\n",
        "wns = WordNetLemmatizer()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "al8O1pT_-MtF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##### Freq Dist of all words for all categories except stopwords\n",
        "tokens = [ y for x in df['text'].values for y in word_tokenize(x) if y.lower() not in stop_words and y.isalpha()]\n",
        "tokens_fdist = FreqDist(tokens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ipEX10oqju3",
        "colab_type": "code",
        "outputId": "00719332-9eff-4288-da3b-55978a6e28aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "#### Freq distribution of words for each category\n",
        "token_cat = {}\n",
        "token_cat_fdist = {}\n",
        "for i in df['target'].unique():\n",
        "  print(target_to_name_map[i])\n",
        "  token_cat[target_to_name_map[i]] = [ y for x in df[df['target'] == i]['text'].values for y in word_tokenize(x) if y.lower() not in stop_words and y.isalpha() ]\n",
        "  token_cat_fdist[target_to_name_map[i]] = FreqDist(token_cat[target_to_name_map[i]]) "
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Entertainment\n",
            "Technology\n",
            "Business\n",
            "Politics\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqvPcs8y_ULh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#### Dataframe to show for each category the top n words\n",
        "n = 100\n",
        "top_words_each_cat = pd.DataFrame({\"Technology\" : [i for i,v in token_cat_fdist[\"Technology\"].most_common(n)],\n",
        "                                      \"Politics\" : [i for i,v in token_cat_fdist[\"Politics\"].most_common(n)],\n",
        "                                      \"Entertainment\" : [i for i,v in token_cat_fdist[\"Entertainment\"].most_common(n)],\n",
        "                                      \"Business\" : [i for i,v in token_cat_fdist[\"Business\"].most_common(n)]},index=range(n))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZ9kHmEc_UJp",
        "colab_type": "code",
        "outputId": "9f552754-8149-42c7-95d1-b8c94b00384d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "source": [
        "top_words_each_cat"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Technology</th>\n",
              "      <th>Politics</th>\n",
              "      <th>Entertainment</th>\n",
              "      <th>Business</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>said</td>\n",
              "      <td>BJP</td>\n",
              "      <td>film</td>\n",
              "      <td>said</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>also</td>\n",
              "      <td>Congress</td>\n",
              "      <td>said</td>\n",
              "      <td>year</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Apple</td>\n",
              "      <td>said</td>\n",
              "      <td>also</td>\n",
              "      <td>market</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>India</td>\n",
              "      <td>Modi</td>\n",
              "      <td>like</td>\n",
              "      <td>India</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>new</td>\n",
              "      <td>party</td>\n",
              "      <td>actor</td>\n",
              "      <td>crore</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>system</td>\n",
              "      <td>manifesto</td>\n",
              "      <td>Game</td>\n",
              "      <td>Reliance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>products</td>\n",
              "      <td>Telangana</td>\n",
              "      <td>every</td>\n",
              "      <td>Tuesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>many</td>\n",
              "      <td>security</td>\n",
              "      <td>among</td>\n",
              "      <td>increase</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>come</td>\n",
              "      <td>Bengal</td>\n",
              "      <td>MCU</td>\n",
              "      <td>time</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>top</td>\n",
              "      <td>Election</td>\n",
              "      <td>Man</td>\n",
              "      <td>banks</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Technology   Politics Entertainment  Business\n",
              "0        said        BJP          film      said\n",
              "1        also   Congress          said      year\n",
              "2       Apple       said          also    market\n",
              "3       India       Modi          like     India\n",
              "4         new      party         actor     crore\n",
              "..        ...        ...           ...       ...\n",
              "95     system  manifesto          Game  Reliance\n",
              "96   products  Telangana         every   Tuesday\n",
              "97       many   security         among  increase\n",
              "98       come     Bengal           MCU      time\n",
              "99        top   Election           Man     banks\n",
              "\n",
              "[100 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwFdicsw_UFQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#### Extract set of words that appear both of any of the two categories\n",
        "from itertools import combinations\n",
        "common_words = []\n",
        "for i in combinations(target_to_name_map.values(),2):\n",
        "  [ common_words.append(x) for x in set(top_words_each_cat[i[0]]).intersection(set(top_words_each_cat[i[1]])) ]\n",
        "\n",
        "common_words = set(list(common_words))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yne8DudF_UCY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#### Dataframe to show for each category the bottom n words\n",
        "n = 100\n",
        "least_words_each_cat = pd.DataFrame({\"Technology\" : [i for i,v in token_cat_fdist[\"Technology\"].most_common()[-n:]],\n",
        "                                      \"Politics\" : [i for i,v in token_cat_fdist[\"Politics\"].most_common()[-n:]],\n",
        "                                      \"Entertainment\" : [i for i,v in token_cat_fdist[\"Entertainment\"].most_common()[-n:]],\n",
        "                                      \"Business\" : [i for i,v in token_cat_fdist[\"Business\"].most_common()[-n:]]},index=range(n))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrhitv74_UAP",
        "colab_type": "code",
        "outputId": "a5a933c8-3454-4c19-d5aa-8d5cc5c5c306",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "source": [
        "least_words_each_cat"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Technology</th>\n",
              "      <th>Politics</th>\n",
              "      <th>Entertainment</th>\n",
              "      <th>Business</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>multiplexes</td>\n",
              "      <td>meters</td>\n",
              "      <td>Cardellini</td>\n",
              "      <td>Marcella</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>cinema</td>\n",
              "      <td>suspect</td>\n",
              "      <td>Christou</td>\n",
              "      <td>Chow</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>discoverability</td>\n",
              "      <td>CSR</td>\n",
              "      <td>Kinchen</td>\n",
              "      <td>shook</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>cataloguing</td>\n",
              "      <td>deserves</td>\n",
              "      <td>Raymond</td>\n",
              "      <td>chugging</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>copyrighting</td>\n",
              "      <td>Seniors</td>\n",
              "      <td>muddied</td>\n",
              "      <td>Pavlik</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>Slate</td>\n",
              "      <td>eldest</td>\n",
              "      <td>deserved</td>\n",
              "      <td>tourism</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>equip</td>\n",
              "      <td>Sharada</td>\n",
              "      <td>recognised</td>\n",
              "      <td>discrepancy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>Lagoon</td>\n",
              "      <td>Venkata</td>\n",
              "      <td>hurtful</td>\n",
              "      <td>happening</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>Viola</td>\n",
              "      <td>Hazare</td>\n",
              "      <td>quickest</td>\n",
              "      <td>Reflecting</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>Velvet</td>\n",
              "      <td>suited</td>\n",
              "      <td>milestone</td>\n",
              "      <td>liquidations</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         Technology  Politics Entertainment      Business\n",
              "0       multiplexes    meters    Cardellini      Marcella\n",
              "1            cinema   suspect      Christou          Chow\n",
              "2   discoverability       CSR       Kinchen         shook\n",
              "3       cataloguing  deserves       Raymond      chugging\n",
              "4      copyrighting   Seniors       muddied        Pavlik\n",
              "..              ...       ...           ...           ...\n",
              "95            Slate    eldest      deserved       tourism\n",
              "96            equip   Sharada    recognised   discrepancy\n",
              "97           Lagoon   Venkata       hurtful     happening\n",
              "98            Viola    Hazare      quickest    Reflecting\n",
              "99           Velvet    suited     milestone  liquidations\n",
              "\n",
              "[100 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGAJV_rX_T5g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTSCZEjhnHBv",
        "colab_type": "text"
      },
      "source": [
        "# **Cleaning text data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urpJz_yV8vFs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from html.parser import HTMLParser\n",
        "import re\n",
        "import string"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXoFBDlFnGzz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "contrac = {'s' : 'is','t':'not','ve' : 'have','d' : 'had', '':'a'}\n",
        "\n",
        "def clean_text(x):\n",
        "  ###### Remove HTML characters\n",
        "  x = HTMLParser().unescape(x)\n",
        "\n",
        "  ##### Treating apostrophes/contraction words\n",
        "  #x = ' '.join([ w.split('\\'')[0].lower()[:-1]+' '+contrac[w.split('\\'')[1].lower()] if '\\'' in w else w for sent in sent_tokenize(x) for w in sent.split()  ])\n",
        "  word_list = []\n",
        "  for sent in sent_tokenize(x):\n",
        "    for w in sent.split():\n",
        "      if '\\'' in w:\n",
        "        w1 = w.split('\\'')[0].lower()[:-1]\n",
        "        try:\n",
        "          c1 = w.split('\\'')[1]/lower()\n",
        "          w_new = w1 + ' '+ contrac[w2]\n",
        "          word_list.append(w_new)\n",
        "        except:\n",
        "          w_new = w1\n",
        "          word_list.append(w_new)\n",
        "      else:\n",
        "        word_list.append(w)\n",
        "    \n",
        "  x = ' '.join(word_list) \n",
        "\n",
        "  ##### Removing stopwords and stemming words to its base form\n",
        "  x = ' '.join([ ps.stem(w) for w in word_tokenize(x) if w not in stop_words])\n",
        "\n",
        "  ##### Remove punctuations\n",
        "  table = str.maketrans('', '', string.punctuation)\n",
        "  x = ' '.join([w.translate(table) for w in word_tokenize(x) ])\n",
        "\n",
        "  ##### Replace digits with 'numeral' string to denote presence of number. This can be used in business category as presence of number in that category is certainly possible\n",
        "  x = ' '.join([ 'numeral' if w.isdigit() else w for w in word_tokenize(x)])\n",
        "\n",
        "  ##### Remove presence of url/https links\n",
        "  url_pattern = r'''(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\".,<>?«»“”‘’]))'''\n",
        "  x = re.sub(url_pattern, ' ', x)\n",
        "\n",
        "  ##### Remove nonascii characters\n",
        "  x = ''.join([chr for chr in x if ord(chr) < 128])\n",
        "\n",
        "  ##### strip and leading/training spaces and convert all words to lowercase\n",
        "  x = x.strip().lower()\n",
        "\n",
        "  return x\n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fiq0ZwrwnL1i",
        "colab_type": "code",
        "outputId": "70661341-c9ad-458b-9c23-6655deb98bff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "news_train['clean_text'] = news_train['STORY'].apply(lambda x : clean_text(x))\n",
        "news_test['clean_text'] = news_test['STORY'].apply(lambda x : clean_text(x))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: The unescape method is deprecated and will be removed in 3.5, use html.unescape() instead.\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOhogG30nLtz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.concat([target_train,news_train.drop(['STORY'],axis = 1)],axis = 1).to_csv('News_Train.csv',index = False)\n",
        "pd.concat([target_test,news_test.drop(['STORY'],axis = 1)],axis = 1).to_csv('News_Test.csv',index = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j33fvsueND_v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ot6E04SRUPeu",
        "colab_type": "text"
      },
      "source": [
        "### **`Classification using Torch`**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIv8yB_158Wl",
        "colab_type": "text"
      },
      "source": [
        "Simple LSTM Baseline model using TorchText"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fiBbpPMVeKd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch \n",
        "from torchtext.data import Field,BucketIterator,TabularDataset,LabelField\n",
        "import torch.nn as nn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJBOFaRwm0Te",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_field = Field(tokenize = word_tokenize,lower = True)\n",
        "label_field = LabelField()\n",
        "datafields = [('SECTION',label_field),('clean_text',text_field)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkjQuzQ_m0RI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = TabularDataset(path = os.path.join(os.getcwd(),'News_Train.csv'),format = \"csv\",skip_header=True,fields=datafields)\n",
        "test = TabularDataset(path = os.path.join(os.getcwd(),'News_Test.csv'),format = \"csv\",skip_header=True,fields=datafields)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfoubHcMp6PT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_field.build_vocab(train,max_size = 5000)\n",
        "label_field.build_vocab(train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ril-Fh3wm0Pa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBR1XmFLm0M9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_iter = BucketIterator(train,batch_size=64,sort_key=lambda x: len(x.clean_text),sort_within_batch=False)\n",
        "test_iter = BucketIterator(test,batch_size=64,sort_key=lambda x: len(x.clean_text),sort_within_batch=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTw5h1UQ2ggT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyI1dOT1m0JT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##### Defining own RNN module\n",
        "class RNN(nn.Module):\n",
        "  def __init__(self,input_dim,embed_dim,hidden_dim,output_dim):\n",
        "    super(RNN,self).__init__()\n",
        "\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.embed = nn.Embedding(input_dim,embed_dim)\n",
        "    self.i2h = nn.Linear(embed_dim + hidden_dim,hidden_dim)\n",
        "    self.i2o = nn.Linear(embed_dim + hidden_dim,output_dim)\n",
        "    self.softmax = nn.LogSoftmax(dim = 1)\n",
        "\n",
        "  \n",
        "  def forward(self,text,hidden):\n",
        "    embeds = self.embed(text)\n",
        "    print(embeds.shape)\n",
        "    embed_hid_concat = torch.cat((embeds,hidden),1)\n",
        "    hidden = self.i2h(embed_hid_concat)\n",
        "    output,hidden = self.i2o(embed_hid_concat)\n",
        "    softmax_output = self.softmax(output)\n",
        "\n",
        "    return softmax_output,hidden\n",
        "\n",
        "  def initHidden(self):\n",
        "    return torch.zeros(1,self.hidden_dim)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qy3i2oZAm0Gz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_dim = len(text_field.vocab)\n",
        "embed_dim = 200\n",
        "hidden_dim = 300\n",
        "output_dim = len(np.unique(target_train))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTihEeXXrVQc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.NLLLoss()\n",
        "learning_rate = 0.001\n",
        "model = RNN(input_dim,embed_dim,hidden_dim,output_dim)\n",
        "init_hidden = model.initHidden()\n",
        "\n",
        "from torch.optim import Adam\n",
        "optimizer = Adam(model.parameters(),lr = learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5bNCSklm0ET",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def train(model,iterator,optimizer,creterion):\n",
        "\n",
        "  epoch_loss = 0\n",
        "  epoch_acc = 0\n",
        "  model.train()\n",
        "\n",
        "  for batch in iterator:\n",
        "    hidden = init_hidden  \n",
        "    print(hidden.shape)\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    preds,hidden = model(batch.clean_text,hidden)\n",
        "    print(preds.shape)\n",
        "    loss = criterion(batch.SECTION,preds)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnhDnZ_Bm0Cs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "outputId": "d524c48c-3970-46c3-cd0c-b93144d81d46"
      },
      "source": [
        "preds,hidden,labels = train(model,train_iter,optimizer,criterion)"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 300])\n",
            "torch.Size([283, 64, 200])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-94-0e4afb53a6b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-93-3b13cc61f539>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, creterion)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclean_text\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSECTION\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-90-526d0059997f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, text, hidden)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0membeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0membed_hid_concat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mi2h\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membed_hid_concat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mi2o\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membed_hid_concat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: invalid argument 0: Tensors must have same number of dimensions: got 3 and 2 at /pytorch/aten/src/TH/generic/THTensor.cpp:603"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xa-xwEu-m0As",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t1 = torch.zeros(283,1,200)\n",
        "t2 = torch.ones(283,64,200)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrh4CVQVmz-g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "cd0483e3-234d-4796-cdfa-661bd5e08e4d"
      },
      "source": [
        "t1.shape"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([283, 1, 200])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZhcwBzYmz8Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "438210d7-2ce6-4b96-f333-f0515df977b5"
      },
      "source": [
        "t2.shape"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([283, 64, 200])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ypLdvl3mz6K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "90f4745d-20cf-41b3-cc52-b7abe2858713"
      },
      "source": [
        "t1.squeeze().shape"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([283, 200])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s56C5xBjmzzR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QMM7PiemzxO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Czw5AKw6mzu6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_C2UIDYmzr9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVNFaQ-7mzqZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5r70_eJmzod",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-Y1gJ9-mzjm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUrjC9immzfe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}